<features> ::= <convolution>
<convolution> ::= layer:conv [out_channels,int,1,32,256] [kernel_size,int,1,2,5] [stride,int,1,1,3] <padding> <activation_function> <bias>
<padding> ::= padding:same | padding:valid
<activation_function> ::= act:linear | act:relu | act:sigmoid
<bias> ::= bias:True | bias:False
<softmax> ::= layer:fc act:softmax out_features:10 bias:True
<learning> ::= <adam> <early_stop> [batch_size,int,1,50,500] epochs:100
<adam> ::= learning:adam [lr,float,1,0.0001,0.1] [beta1,float,1,0.5,0.9999] [beta2,float,1,0.5,0.9999] [weight_decay,float,1,0.000001,0.001]
<early_stop> ::= [early_stop,int,1,10,20]